##Discrete random variable
###Random variable
A random variable is a mapping/function from the sample space S to the real number line.

A random variable is said to be discrete if its values assume integer points on the real number line. In other words, the outcomes are countably finite/infinite.

####Probability density function
For a discrete random variable X, the probability P(X=x) is denoted by p(x) and called the probability density (or mass) function. It satisfies:

* \\(
P(X=x) \geq 0
\\) or equivalently \\(
p(x) \geq 0
\\)

* \\(
\sum{P(X=x)}=1
\\)

* \\(
0 \geq P(X=x) \geq 1
\\)

Example: To obtain a model for campus Internet security in NCCU, the number of attacks occurring each week was observed over a period of 1 year. It was found that
0 attacks occurred in each of 9 weeks; 1 attack occurred in each of 14 weeks 2 attacks occurred in each of 13 weeks; 3 attacks occurred in each of 9 weeks 4 attacks s occurred in each of 4 weeks; 5 attacks occurred in each of 2 weeks 6 attacks occurred in each of 1 weeks
By obtaining the relative frequency of attacks, we can estimate the distribution using R 
```r
 attacks=c(9, 14, 13, 9, 4, 2, 1)
 probability=attacks/sum(attacks)
 probdens=round(probability, 2)
```
Write out the approximated distribution.

Visualize the pdf > Attacks=0:6
```r
plot(0:6, probdens, xlab= "# of attacks per week", ylab= "p(x)", type= "h")
```
We estimate probabilities from the observed frequencies of attacks over a year. Our hope is that the estimated probabilities are not too far away from the true (but unknown) probabilities. The greater the number of observations, the more accurate the estimated probabilities are. 
####Cumulative distribution function (cdf): 
The cumulative distribution function, F(x), of a discrete random variable X is defined by
\\(
F(x)=\sum{p(k)}=P(X \leq x)
\\)

We actually can show that
F(x)-F(x-1)=p(x)(i.e., P(X=x))

For the aforementioned number of attacks, write out the cdf.
```r
cumprob=cumsum(probdens)
plot(0:6, cumprob, xlab= "# of attacks", ylab= "probability", type= "S")
```


###Benford’s law
It was long assumed that the first digits of serial numbers ranged from 1 to 9 with equal likelihood (exercise – write a uniform pdf). Back in 1930s Benford showed that the number 1 occurs more frequently as a first digit than all other numbers. After examining diverse data sets, he found that the number 1 appeared as a first digit approximately 30% of the time in all cases. Hill (196) proposed a function that approximates the first digit frequencies.

\\(
f(x)=\log (1+frac{1}{x}),x=1,2...9
\\)

Let’s check this function in R. 
```
x=1:9
prob=round(log10(1+1/x), 3)
plot(x, prob, type=“h”)
```

###Summarizing random variables
The expected value or mean of a discrete random variable is defined as the weighted average of all possible values. The weights are the probabilities p(x) (P(X=x)) of respective values x
\\(
\mu=E(X)=\sum_x xp(x)
\\)
A more generic form is 
\\(
E(g(X))= \sum{g(x)p(x)}
\\)

####Now go back to the number of attacks discussed earlier, compute the expected value
```r
 x=0:6
 probability=c(9/52, 14/52, 13/52, 9/52, 4/52, 2/52, 1/52)
 sum(x*probability)
```

In addition to the central tendency, the spread of a random variable is of great interest too.
The most commonly used measure of spread is called `variance`
\\(
V(X)=\sigma^2=E(X-\mu)^2=\sum_x{(x-\mu)^2p(x)}
\\)

###使用之前的機率抽樣
```r
attacks_100=sample(c(0:6), 100, replace=T, prob=probability)
```

###Properties of mean and variance
Suppose the monetary loss due to the number of attacks X can be estimated in $USD using the function: Loss=10X+200. Compute (a) the expected weekly loss (b) the variance of the expected weekly loss. As such, we need to know E(10X+200) and V(10X+200).
Below are some useful properties. For any arbitrary constant c:
\\(
E(X+c)=\sum_x{(x+c)p(x)}=\sum_x{xp(x)}+c\sum_x{p(x)}=E(X)+c
\\
V(cX)=c^2V(X)
\\)

##Some discrete distributions
\\(
ddist(x,\theta) \, return \, p(x)=P(X=x)
\\
pdist(x,\theta) \, return \, F(x)=P(X\leq x)
\\
qdist(p,\theta) \, return \, the \, smallest \, q \, for \, which \, F(q)=P(X\leq q)\geq p
\\
rdist(n,\theta) \, returns \, a \, vector \, of \, n \, pseudo-random \, numbers \, from \, the \, distribution \, dist
\\) 


####dgeorm(x,prob)
x:number of trial `before` the first success/failure

###Geometric distribution

Example: Products produced by a machine have a 3% defective rate. What is the probability that the first defective occurs in the fifth item inspected? What is the probability that the first defective occurs in the first five inspections?
 dgeom(x=4, prob=0.03) #第四個是defective的機率
 pgeom(4, 0.03) #在第四個之前(包含第四個)抽到defective的機率


###Bernoulli distribution
Suppose an experiment has a sample space that consists of two outcomes, a “success” with probability p and a “failure” with probability 1-p, we can model the outcome as a Bernoulli random variable X with the pdf
\\(
P(X=1)=p
\\)

\\(
where \, 0\leq p \leq 1
\\)

\\(
P(X=0)=1-p
\\)

In R, you use the Bernoulli distribution using:

```r
dbinom(x, size=1, prob=p,...).
```

###Binomial distribution
有一個實驗會執行獨立n次，每次會有成功(機率p)或是失敗(機率1-p)兩種可能,
An experiment has n independent trials, and each trial has a “success” with probability p and a “failure” with probability 1-p. We can model the number of successes as a binomial random variable X with its pdf p(x)
P(x):成功x次的機率

\\(
P(X=x)=   \begin{pmatrix}
        n \\
        x \\
        \end{pmatrix}
        p^x(1-p)^{n-x},x=0,1,2,3....,n
\\)

We can also easily show that the Bernoulli distribution is a special case with n=1.
Example: 20% of integrated circuit chips on a production line are known to be defective. A sample of 20 chips is selected at regular intervals for inspection. Up to how many defectives k will the sample contain at least 95% certainty? We want to find k such that
####至少95%的機會，我們抽到的瑕疵品會小於等於k。
\\(
P(X\leq k) \geq 0.95 
\\)

```r
 qbinom(0.95, size=20, prob=0.2)
```
驗證
```r
def=rbinom(10000,size=20,prob=0.2)
sum(def<=7)/10000
```


####抽20個樣品,瑕疵品會小於等於7個的機率。
\\(
P(X \leq 7)
\\)

```r
 pbinom(7,20,0.2)
```


###Poisson distribution (check help(dpois) in R)
Poisson distribution is probably one of the famous discrete distributions. This distribution is
used as a model for rare events, and event occurring at random over time and space. I cannot
over-emphasize the importance of Poisson distribution as it has many important applications
in inventory theory, queuing theory, etc. Its pdf p(x) is
\\(
P(X=x)={\lambda^xe^{-\lambda}}/{x!}
\\)


###Negative binomial distribution (check help(dnbinom) in R)


###問題
Geometric distribution
